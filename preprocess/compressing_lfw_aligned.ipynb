{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "085e76a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mtcnn\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2 # opencv\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3312d1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to align the eyes horizontally\n",
    "def align_eyes_horizontally(image, keypoints):\n",
    "    left_eye = keypoints['left_eye']\n",
    "    right_eye = keypoints['right_eye']\n",
    "    # Calculate the angle to align the eyes\n",
    "    dY = right_eye[1] - left_eye[1]\n",
    "    dX = right_eye[0] - left_eye[0]\n",
    "    angle = np.degrees(np.arctan2(dY, dX))\n",
    "\n",
    "    # Get the center of the eyes\n",
    "    eyes_center = ((left_eye[0] + right_eye[0]) // 2, (left_eye[1] + right_eye[1]) // 2)\n",
    "\n",
    "    # Rotate the image around the center of the eyes\n",
    "    M = cv2.getRotationMatrix2D(eyes_center, angle, 1)\n",
    "    aligned_image = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    return aligned_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4691b083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract a single face from a given photograph\n",
    "def extract_face(filename, required_size=(160, 160)):\n",
    "    # load image from file\n",
    "    image = Image.open(filename)\n",
    "    # convert to RGB, if needed\n",
    "    image = image.convert('RGB')\n",
    "    # convert to array\n",
    "    pixels = np.asarray(image)\n",
    "    # create the detector, using default weights\n",
    "    detector = MTCNN()\n",
    "    # detect faces in the image\n",
    "    results = detector.detect_faces(pixels)\n",
    "    #### print('results - ', results)\n",
    "    \n",
    "    if len(results) == 0:\n",
    "        print('No face DETECTED. Returning None')\n",
    "        return None  # No face detected, return None\n",
    "    \n",
    "    # extract the bounding box from the first face\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    # deal with negative pixel index\n",
    "    x1, y1 = abs(x1), abs(y1)\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    # extract the face\n",
    "    face = pixels[y1:y2, x1:x2]\n",
    "    #### print('face - ', face)\n",
    "    \n",
    "    # Align the face\n",
    "    keypoints = results[0]['keypoints']\n",
    "    aligned_face = align_eyes_horizontally(face, keypoints)\n",
    "    \n",
    "    # resize pixels to the model size\n",
    "    image = Image.fromarray(aligned_face)\n",
    "    image = image.resize(required_size)\n",
    "    face_array = np.asarray(image)\n",
    "    return face_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e638522b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D50DDE95E8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D50F1C5798> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "loaded 213 sample for class: Colin_Powell\n",
      "loaded 109 sample for class: Donald_Rumsfeld\n",
      "loaded 477 sample for class: George_W_Bush\n",
      "loaded 99 sample for class: Gerhard_Schroeder\n",
      "loaded 130 sample for class: Tony_Blair\n",
      "(1028, 160, 160, 3) (1028,)\n",
      "loaded 23 sample for class: Colin_Powell\n",
      "loaded 12 sample for class: Donald_Rumsfeld\n",
      "loaded 53 sample for class: George_W_Bush\n",
      "loaded 10 sample for class: Gerhard_Schroeder\n",
      "loaded 14 sample for class: Tony_Blair\n",
      "(112, 160, 160, 3) (112,)\n"
     ]
    }
   ],
   "source": [
    "def load_face(dir):\n",
    "    faces = list()\n",
    "    # enumerate files\n",
    "    for filename in os.listdir(dir):\n",
    "        path = dir + filename\n",
    "        face = extract_face(path)\n",
    "        faces.append(face)\n",
    "    return faces\n",
    "\n",
    "def load_dataset(dir):\n",
    "    # list for faces and labels\n",
    "    X, y = list(), list()\n",
    "    for subdir in os.listdir(dir):\n",
    "        path = dir + subdir + '/'\n",
    "        faces = load_face(path)\n",
    "        labels = [subdir for i in range(len(faces))]\n",
    "        print(\"loaded %d sample for class: %s\" % (len(faces),subdir) ) # print progress\n",
    "        X.extend(faces)\n",
    "        y.extend(labels)\n",
    "    return np.asarray(X), np.asarray(y)\n",
    "\n",
    "# load train dataset\n",
    "trainX, trainy = load_dataset('lfw-deepfunneled/data/train/')\n",
    "print(trainX.shape, trainy.shape)\n",
    "# load test dataset\n",
    "testX, testy = load_dataset('lfw-deepfunneled/data/test/')\n",
    "print(testX.shape, testy.shape)\n",
    "\n",
    "# save and compress the dataset for further use\n",
    "np.savez_compressed('lfw_train_test_compressed_aligned.npz', trainX, trainy, testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512471ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
